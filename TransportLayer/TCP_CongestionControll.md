# TCP 혼잡제어

전통적인 TCP는 네트워크 지원 혼잡제어 보다는 종단 간의 혼잡제어를 사용한다.  

## 전통적인 TCP의 혼잡제어  

TCP가 취한 방식은 네트워크 혼잡에 따라 연결에 트래픽을 보내는 전송률을 각 송신자가 제한하는 것이다.  
만약 TCP 송신자가 자신과 목적지간의 경로에서 혼잡이 없음을 감지하면 송신자는 송신율을 높인다.  
반면 송신자가 경로 사이에 혼잡을 감지하면 송신율을 줄인다.  

첫째, TCP 송신자는 자신의 연결에 송신자 전송 트래픽 전송률을 어떻게 제한하는가?  
둘째, TCP 송신자는 자신과 목적지 사이 경로의 혼잡을 어떻게 감지하는가?  
셋째, 송신자는 종단간의 혼잡을 감지함에 따라 송신율을 변화시키기 위해 어떤 알고리즘을 사용하는가?  

먼저 TCP 송신자가 연결로 트래픽을 보내는 전송률을 어떻게 제한하는지 살펴보자.  
TCP 연결 양 끝의 각 호스트는 수신버퍼와 송신버퍼, 그리고 몇 가지 추가 변수로 구성되는 것을 보았다.  

송신 측에서 동작하는 TCP혼잡 제어 매커니즘은 추가적인 변수인 혼잡윈도를 추적한다.  
cwnd로 표시되는 혼잡윈도는 TCP 송신자가 네트워크로 트래픽을 전송할 수 있는 속도에 제약을 가한다.  
특히 송신하는 쪽에서 확인응답이 안된 데이터의 양은 cwnd와 rwnd의 최솟값을 초과하지 않을 것이다.  

$LastByteSent-LastByteAked <= min(cwnd, rwnd)$  

혼잡제어에 집중하기 위해, 수신윈도의 제약조건을 무시할 수 있을 정도로 TCP 수신버퍼가 매우 크다고 하자.  
그러므로 송신자의 확인응답이 안된 데이터의 양은 오로지 cwnd에 의해 한정된다.  
또한 송신자가 항상 보낼 데이터가 있다고 가정한다. 즉, 혼잡윈도의 모든 세그먼트는 전송된다.  

위의 제약은 송신자에서 확인응답이 안된 데이터의 크기를제한하고 그에 따라 송신자의 송신 속도를 간접제한한다.  
이를 이해하기 위해 손실과 패킷 전송 지연이 무시될 수 있는 연결을 고려하자.  

그러면 대략 매 왕복시간(RTT)의 시작 때, 송신자는 cwnd 바이트 만큼의 데이터를 전송할 수 있고, RTT가 끝나는 시점에 대한 확인응답을 수신한다.  
그러므로 송신자의 송신속도는 대략 cwnd/RTT 바이트/초이다.  
cwnd값을 조정하여 송신자는 링크에 데이터를 전송하는 속도를 조절할 수 있다.  

이제 어떻게 TCP 송신자가 자신과 목적지 사이의 경로에 혼잡이 존재하는지를 감지하는지 살펴보자.  
타임아웃 또는 수신자로부터 3개의 중복된 ACK의 수신이 발생했을 때, TCP 송신자 측에 '손실 이벤트'가 발생했다고 가정하자.  

과도한 혼잡이 발생하면, 경로에 있는 하나 이상의 라우터 버퍼들이 오버플로되고 그 결과 데이터그램이 버려진다.  
버려진 데이터그램은 송신측에서 손실이벤트를 발생시키고, 송신자와 수신자 사이의 경로상에 혼잡이 발생했음을 알게된다.  

손실 이벤트가 발생하지 않는 네트워크가 혼잡이 없는 경우가 되는 더 낙관적인 경우를 고려해보자.  

이  경우 이전에 확인응답 안된 세그먼트들에 대한 확인응답들이 TCP 송신자에서 수신될 것이다.  
TCP는 모든 것이 올바르게 동작하고 있다는 표시로서 이 확인응답의 도착을 받아들일 것이며, TCP는 혼잡 윈도 크기를 증가시키기 위해 확인응답을 사용할 것이다.  

확인응답이 상대적으로 늦은 속도로 도착한다면 혼잡 윈도는 상대적으로 낮은 속도로 증가하는 반면에, 확인응답이 높은 속도로 도착한다면 혼잡윈도는 더 빨리 증가할 것이다.  
TCP는 확인응답을 혼잡윈도 크기의 증가를 유발하는 트리거 또는 클록으로 사용하므로 TCP는 자체 클로킹이라고 한다.  

전송률을 제어하는 cwnd값을 조정하는 매커니즘이 주어졌을 때, 중요한 질문이 남게 된다.  
즉, 어떻게 TCP송신자가 자신이 송신할 속도를 결정하는가?  
만약 전체 TCP 송신자들이 너무 빠르게 송신하면 네트워크가 혼잡해져 혼잡 붕괴가 나타날 것이다.  

TCP 송신자들이 너무 조심스럽고 너무 천천히 송신한다면, 네트워크 내의 대역폭을 충분히 활용하지 못하게 될 것이다.  
즉, TCP 송신자들은 네트워크를 혼잡시키지 않고 더 높은 전송률로 보낼 수도 있는 것이다.  

TCP 송신자들은 가용한 대역폭을 모두 사용하는 동시에 반면 네트워크를 혼잡시키지 않는 전송률을 어떻게 결정할 수 있을까?  

1. 손실된 세그먼트는 혼잡을 의미하며, 이에 따라 TCP 전송률은 한 세그먼트를 손실했을 때 줄여야 한다: 타임 아웃 이벤트나 4개의 확인응답(원래의 ACK와 3개의 중복 ACK)의 수신은 손실 세그먼트의 재전송을 야기한다.  
혼잡 제어 관점에서 문제는 TCP 송신자가 혼잡윈도 크기와 이에 따른 추론된 손실 이벤트에 대응하는 전송률을 줄이는 방법이다.  

2. 확인응답된 세그먼트는 네트워크가 송신자의 세그먼트를 수신자에게 전송된다는 것이고 이에따라 이전에 확인응답 되지 않은 세그먼트에 대해 ACK가 도착하면 송신자의 전송률은 증가할 수 있다: 확인응답의 도착한 세그먼트들이 송신자로부터 수신자까지 성공적으로 전송되었고 네트워크는 혼잡하지 않는다. 즉, 모든 것이 좋다는 묵시적 표시로 받아들여 진다. 따라서 혼잡윈도 크기가 증가할 수 있다.  

3. 대역폭 탐색: 혼잡이 없는 출발지에서 목적지까지의 경로를 표시하는 ACK와 혼잡한 경로를 표시하는 손실이벤트가 주어지면, TCP의 전송률을 조정하는 TCP의 전략은 TCP 송신자로 하여금 손실 이벤트가 발생할 때 까지는 ACK가 도착함에 따라 전송률을 증가시키게 하는 것이고, 손실 이벤트가 발생한 시점에서 전송률을 줄이는 것이다. 그러므로 TCP 송신자는 혼잡이 발생한 시점까지 전송률을 증가시키고 그 시점 이후부터는 줄인 후 다시 혼잡이 시작했는지를 보기 위한 탐색을 시작한다. TCP 송신자의 행동은 마치 자기가 좋아하는 것을 조금씩 더 요구하다가 결국 안된다고 야단맞고 물러났다가 다시 그 후 조금씩 요구하는 아이들과 비슷하다.  

네트워크에의한 혼잡상태의 어떠한 명시적인 신호가 없으며, 각 TCP 송신자들은 다른 TCP 송신자들과 비동기적 로컬 정보에 근거해 동작한다.  
TCP 혼잡제어 알고리즘은 다음과 같은 중요한 세 가지 구성요소를 갖는다.  
1. 슬로 스타트
2. 혼잡회피
3. 빠른 회복

슬로 스타트와 혼잡 회피는 TCP의 필수 요소다.  
다만 수신된 ACK에 대응하여 cwnd 크기를 얼마나 증가시키냐는 것이 서로 다르다.  
조만간 슬로 스타트는 혼잡 회피보다 더 빨리 cwnd크기를 증가시키는 것을 보게될 것이다.  
빠른회복은 권고되지만, TCP 송신자들에게 필수사항은 아니다.  


## 슬로 스타트  

TCP 연결이 시작될 때, cwnd의 값은 일반적으로 1MSS로 초기화되고, 그 결과 초기 전송률은 대략 MSS/RTT가 된다.  
예를 들어 MSS=500바이트이고 RTT=200ms이면, 그 결과로 초기 전송률은 단지 약 20kbps가 된다.  

TCP 송신자에게 가용 대역폭은 MSS/RTT보다 훨씬 클 것이므로, TCP 송신자는 가용 대역폭의 양을 조속히 찾고자 한다.  
그러므로 슬로 스타트 상태에서는 cwnd값을 1MSS에서 시작하며, 한 전송 세그먼트가 첫 번째로 확인응답을 받을 때 마다 1MSS씩 증가한다.  

TCP 송신자는 첫 번째 세그먼트를 네트워크로 보내고 확인응답을 기다린다.  
이 확인응답이 도착하면 TCP 송신자는 하나의 MSS 만큼 혼잡윈도를 증가시키고 2개의 MSS를 전송한다.  
이 세그먼트가 확인응답하면, 송신자는 각 확인응답 세그먼트에 대해 하나의 MSS 만큼 혼잡윈도를 증가시킨다.  

그러면 4개의 TCP MSS 혼잡 윈도가 주어지게 되고, 이러한 과정을 반복한다.  
그래서 TCP 전송률은 작은 값으로 시작하지만 슬로 스타트 단계 동안 지수적으로 증가한다.  

그러나 이 지수적 증가는 언제 끝나는 것인가?  

첫 번째, 만약 타임아웃으로 표시되는 손실 이벤트(즉, 혼잡)가 있을 경우 TCP 송신자는 cwnd값을 1로 설정하고 새로운 슬로 스타트를 시작한다.  
또한 TCP 송신자는 두 번째 상태변수인 ssthresh(slow start threshold, 슬로 스타트 임계값)의 값을 cwnd/2로 정한다.  

슬로 스사트가 끝나는 두 번째 방법은 ssthresh값과 직접적으로 연관된다.  
ssthresh는 혼잡이 마지막으로 검출된 시점에서의 cwnd 값의 반이므로, 이 값에 도달하거나 지나칠 때 cwnd를 계속 두 배로 하는 것은 신중하지 못한 일이다.  
따라서 cwnd값이 ssthresh와 같으면, 슬로 스타트는 종료되고 TCP는 혼잡 회피모드로 전환된다.  

세 번쨰 방법은 만약 3개의 중복 ACK가 검출되면, TCP는 빠른 재전송을 수행하여 빠른 회복 상태로 들어간다.  


## 혼잡 회피  

혼잡 회피 상태로 들어가는 시점에서 cwnd의 값은 대략 혼잡이 마지막으로 발견된 시점에서의 값의 반이 된다.  
그러므로 RTT마다 cwnd값을 두배로 하기보다는 TCP는 좀 더 보수적인 접근법을 채택하여 RTT마다 하나의 MSS만큼 cwnd값을 증가시킨다.  

일반적인 접근 방식은 새로운 승인이 도착할 때마다 TCP 송신자가 cwnd를 MSS 바이트(MSS/cwnd)만큼 증가시키는 것이다.  
예를 들어 MSS가 1460바이트이고 cwnd가 14600바이트일 때, 10개의 세그먼트가 한 RTT내에 송신될 수 있다.  
각 ACK는 1/10MSS 만큼씩 혼잡윈도를 증가시키고, 이에 따라 모든 10개의 세그먼트가 수신되었을 때의 ACK들 후에 하나의 MSS 만큼만 혼잡윈도를 증가시킨다.  

그러나 언제 혼잡 회피의 선형 증가가 끝날 것인가? 

TCP 혼잡 회피 알고리즘은 타임아웃이 발생했을 떄, 슬로스타트의 경우와 같이 동작한다.  
cwnd의 값은 1MSS로 설정하고, ssthresh의 값은 손실 이벤트가 발생할 때의 cwnd값의 반으로 설정한다.  

그러나 손실 이벤트가 3개의 중복 ACK 이벤트에의해 야기된다는 점을 생각해보자.  
이 경우 네트워크 송신자로부터의 세그먼트를 수신자에게 계속 전달되고 있다.  
따라서 이러한 타입의 손실 이벤트에 대한 TCP 동작은 타임아웃 표시 손실보다 덜 과감해야 한다.  

TCP는 3개의 중복 ACK를 수신한 시점에서 cwnd의 값을 반으로 줄이고 ssthresh 값을 cwnd 값의 반으로 기록한다.  
이후 빠른 회복 상태로 들어간다.  

## 빠른 회복

빠른 회복에서는 cwnd 값을 손실된 세그먼트에 대해 수신된 모든 중복 ACK에 대해 1MSS 만큼씩 증가시킨다.  
손실된 세그먼트에 대한 ACK가 도착하면 TCP는 혼잡회피 상태로 들어간다.  

만약 타임아웃 이벤트가 발생하면 빠른 회복은 슬로 스타트 및 혼잡회피에서와 같은 동작을 수행한다.  
즉, cwnd 값은 1MSS로 하고 ssthresh값을 손실 이벤트가 발생할 때의 cwnd값의 반으로 한다.  

빠른 회복은 권고사항이지만 필수는 아니다.  
TCP 타호라 불리는 초기 TCP 버전은 타임아웃으로 표시되거나 3개의 중복 ACK로 표시되는 손실이 발생하면 무조건 혼잡 윈도를 1로 줄이고, 슬로 스타트 단계로 들어간다.  
새로운 TCP 버전인 TCP 리노는 빠른 회복을 채택했다.  

임계값은 초기에는 둘 다 8MSS다. 처음 8번의 전송동안에는 타호와 리노가 동일한 행동을 취한다.  
혼잡 윈도는 슬로 스타트 동안에 지수적으로 증가하고, 4번째 송신에서 임계값에 이른다.  
8번째 송신 후에 3개의 중복 ACK가 발생할 때 까지 혼잡윈도는 선형으로 증가한다.  

이 손실 이벤트가 발생했을 때 혼잡 윈도가 12MSS임을 주목하자.  
그러면 ssthresh의 값은 0.5cwnd = 6MSS가 된다.  
TCP 리노는 혼잡 윈도가 9MSS로 설정되고 선형적으로 증가한다.  
TCP 타호에서 혼잡윈도는 1MSS로 설정되고 ssthresh에 도다할 때 까지 지수적으로 증가하고, 그 이후에는 선형으로 증가한다.  

TCP 오류 제어/재전송과 TCP 혼잡제어의 차이를 구별하는 것도 중요하지만 TCP의 이러한 두 가지 면이 어떻게 떼려야 뗼 수 없는 관계에 있는지를 이래하는 것도 매우 중요하다.  

## TCP 혼잡제어: 복습

연결이 시작되고 초기 슬로 스타트 기간을 무시하고, 손실이 타임아웃이 아니라 3개의 중복 ACK로 표시된다고 가정하자.  

TCP의 혼잡제어는 RTT마다 1MSS씩 cwnd의 선형(가법적인)증가와 3개의 중복 ACK로의 절반화(승법적 감소)로 구성된다.  
이러한 이유로 TCP 혼잡제어는 종종 가법적 증가, 승법적 감소(Additive-Increase, Multiplicative Decrease, AIMD)의 혼잡제어 형식이라고 불린다.  

AIMD 혼잡제어는 '톱니'동작이 생기게 한다.  
또한 이 그림은 대역폭에 대한 TCP '탐색'의 초기 직관을 보여준다.  
즉, TCP는 3개의 중복 ACK 이벤트가 발생할 때 까지 선형으로 그 혼잡윈도 크기를 증가시킨다(전송률 증가).  
그리고 나서는 혼잡 윈도 크기를 반으로 감소시키지만, 다시 추가적인 가용 대역폭이 있는지를 탐색하기 위해 선형으로 증가시킨다.  

## TCP 큐빅  

TCP 리노의 혼잡제어에 대한 가법적 증가 승법적 감소 접근 방식을 고려해볼 때 이것이 패킷 손실 임계값보다 바로 아래의 패킷 전송 속도를 '탐색'하는 가장 좋은 방법인지 자연스럽게 궁금해할 수 있다.  
실제로 전송속도를 절반으로 줄인 다음 시간이 지남에 따라 다소 천천히 증가시키는 것은 지나치게 신중한 것일 수 있다.  

패킷 손실이 발생한 혼잡한 링크의 상태가 많이 변경되지 않은 경우 전송 속도를 더 빠르게 높여 손실  전 전송속도에 근접한 다음 대역폭을 신중하게 조사하는 것이 좋을 것이다.  
이러한 통찰력은 TCP 큐빅으로 알려진 TCP 특징의 핵심이다.  

TCP 큐빅은 TCP 리노와 약간 다르다.  
즉, ACK 수신시에만 혼잡 윈도를 늘리고 슬로 스타트 단계와 빠른 회복 단계는 동일하게 유지되지만 큐빅은 다음과 같이 혼잡 회피 단계가 수정되었다.  

손실이 마지막으로 감지되었을 떄 TCP의 혼잡제어 윈도 크기를 Wmax라고 하고 손실이 없다고 가정할 때 TCP 큐빅의 윈도 크기가 다시 Wmax에 도달하는 미래 시점을 K시각이라고 하자. 
몇 가지 조율 가능한 큐빅 매개변수들이 K값 즉 프로토콜의 혼잡 윈도 크기가 얼마나 빨리 Wmax에 도달하는 가를 결정한다.  

큐빅은 혼잡 윈도를 현재 시각 t와 K시각 사이 거리의 세제곱 함수로 증가시킨다.  
따라서 t가 K에 가까울 때 보다 t가 K에서 더 멀리 떨어지면 혼잡 윈도 크기 증가가 훨씬 더 커진다.  
즉, 큐빅은 손실 전 속도인 Wmax에 가까워지도록 TCP 전송 속도를 빠르게 증가시킨다음, Wmax에 가까워지면 대역폭을 조심스럽게 탐지한다.  

t가 K보다 크면 큐빅은 다음을 의미한다.  
t가 여전히 K에 가까울 떄는 큐빅의 혼잡 윈도 증가가 작으나(손실을 유발하는 혼잡 수준이 많이 변경되지 않은 경우 좋음) t가 K를 크게 초과함에 따라 급격히 증가한다는 것이다.  
이로 인해 손실을 유발한 링크의 정체 수준이 크게 변경된 경우 큐빅이 새 작동지점을 더 빨리 찾을 수 있다.  

이러한 규칙에 따라 TCP 리노와 TCP 큐빅의 이상적인 성능 비교를 해보자  
슬로 스타트 단계가 t0에서 끝나는 것을 볼 수 있다.  
그런 다음 t1, t2, t3에서 혼잡 손실이 발생하면 큐빅은 Wmax에 가깝게 더 빠르게 증가한다.  
따라서 리노보다 더 많은 처리량을 누린다.  

TCP 큐빅이 혼잡 임계값 바로 아래에서 가능한한 오랫동안 흐름을 유지하려고 한다.  
t3에서 정체 수준이 눈에 띄게 감소하여 TCP 리노와 TCP 큐빅모두 Wmax보다 높은 전송 속도를 달성하게 된다.  

2000년 경에는 거의 TCP 리노를 실행하고 있었지만 최근 측정에서는 인기있는 웹 서버의 50%가 TCP 큐빅을 사용하고 있었다.  
또한 리눅스 OS에서 사용되는 TCP의 기본 버전이다.  


## TCP 리노 처리율의 거시적 설명  

톱니 모양의 TCP 리노 동작이 주어지면, 장시간 연결된 TCP 연결의 평균 처리율을 생각해보는 것은 당연하다.  
이 분석에서는 타임 아웃 이벤트 발생 후에 발생하는 슬로 스타트 단계를 무시할 것이다.  

하나의 특정 RTT동안 TCP가 데이터를 보내는 비율은 혼잡 윈도와 현재 RTT의 함수이다.  
윈도 크기가 w바이트 이고 왕복 시간은 RTT 초이면, TCP의 전송률은 대략 w/RTT이다.  

TCP는 손실 이벤트가 발생할 때까지 RTT당 하나의 MSS만큼 w를 증가시켜서 추가 대역폭을 얻는다.  
여기서 손실 이벤트가 발생하는 시점의 w값을 W라고 표기하자.  

RTT와 W가 대체로 링크동안 일정하다고 가정하면 TCP 전송률은 W/(2RTT)부터 W/RTT까지의 범위를 갖는다.  
이런 가정은 TCP 안정 상태 동작에 매우 간단한 거시 모델을 제시한다.  

비율이 W/RTT까지 증가할 때, 네트워크는 연결로부터 온 패킷을 버린다.  
그러면 비율은 반으로 줄어들고, 혼잡 윈도가 다시 W/RTT에 도달할 때 까지 왕복시간 당 MSS/RTT 만큼 증가한다.  
이 과정을 반복한다.  

TCP 처리량이 양 극값 사이에서 선형적으로 증가하므로 다음을 얻게된다.  
연결의 평균 처리율 = 0.75/RTT  



## 네트워크 지원 명시적 혼잡 알림과 지연 기반 혼잡제어  

TCP 송신자는 네트워크에서 명시적인 혼잡제어 표시를 수신하지 않는 대신 관찰된 패킷 손실을 통해 혼잡을 추론한다.  

## 명시적 혼잡알림

명시적 혼잡 알림은 인터넷 내에서 수행되는 네트워크 지원 혼잡 제어의 한 형태로, TCP와 IP가 모두 관련되어 있다.  
네트워크 계층에서 IP 데이터그램의 헤더의 서비스 유형 필드에 있는 2비트가 ECN(명시적 혼잡 알림, Explicit Congestion Notification)에 용된다.  

ECN비트의 한 설정은 라우터가 정체를 겪고 있음을 나타내기 위해 라우터에서 사용된다.  
그런 다음 이 혼잡 표시는 표시된 IP 데이터그램에서 목적지 호스트로 전달되고 송신 호스트에게 알린다.  

언제 라우터가 혼잡해지는가는 정의하지 않는다.  
그 결정은 라우터 공금 업체가 가능하게 하고 네트워크 운영자가 결정하는 구성 결정이다.  

그러나 직관적으로 손실이 발생하기 전에 혼잡 시작을 송신자에게 알리기 위해 혼잡 알림 비트를 설정할 수 있는 것이다.  
ECN비트의 두 번째 설정은 발신 호스트가 라우터에게 송신자와 수신자가 ECN을 사용할 수 있음을 알리고, 이에 따라 ECN으로 표시된 네트워크 혼잡에 대한 응답 조치를 취할 수 있음을 알리는데 사용된다.  

수신 호스트의 TCP가 수신 데이터그램을 통해 ECN 혼잡 알림 표시를 수신하면 수신 호스트의 TCP는 수신자-송신자 TCP ACK 세그먼트의 ECE(Explicit Congestion Notification Echo, 명시적 혼란 알림 에코)비트를 설정하여 송신 호스트의 TCP에 혼잡을 알린다.  

TCP 송신자는 빠른 재전송을 사용하여 손실된 세그먼트에 반응하는 것처럼 혼잡 윈도를 절반으로 줄여 혼잡 알림 표시가 있는 ACK에 반응하고 다음 전송되는 TCP 수신자 헤더에 CWR(Congestion Window Reduce) 비트를 1로 설정한다.  


## 지연 기반 혼잡제어

위의 ECN에서 혼잡해지는 라우터는 그 라우터에서 버퍼가 가득 차서 패킷들이 삭제되기 전에 송신자에게 혼잡 시작을 알리는 혼잡 알림 비트를 사용할 수 있다.  
송신자는 이를 통해 패킷 손실 이전에 더 일찍 전송 속도를 줄일 수 있으므로 값비싼 패킷 손실 및 재전송을 피할 수 있게 된다.  

두 번째 혼잡 회피 접근 방식은 지연 기반 접근 방식을 취하며 패킷 손실이 발생하기 전에 혼잡 시작을 사전에 감지하는 것이다.  

TCP 베가스에서는 모든 확인응답된 패킷에대한 출발지에서 목적지 까지 경로의 RTT를 측정한다.  
RTTmin을 송신자에게 측정한 RTT값 중의 최솟값이라고 하자.  
이는 경로가 정체되지 않고 패킷이 최소 대기 지연을 경험할 때 발생한다.  

TCP 베가스의 혼잡 윈도 크기가 cwnd인 경우 혼잡하지 않을 때의 처리율은 cwnd/RTTmin이 된다.  

실제 송신자가 측정한 처리량이 이 값에 가까우면 경로가 아직 정체되지 않았고 따라서 TCP 전송 속도가 증가할 수 있다는 것이다.  
그러나 실제 송신자가 측정한 처리량이 혼잡하지 않을 떄의 처리율보다 현저히 낮으면 경로가 혼잡하고 TCP 베가스 송신자는 전송 속도를 낮춘다.  

TCP 베가스는 TCP 송신자가 파이프를 가득 채우되 그 이상으로 채우지 않도록 해야된다. 는 직관적인 원칙에 동작한다.  

'파이프가 가득찬 상태로 유지'는 링크가 계속 바쁘게 전송하는 소중한 작업을 수행함을 의미한다. '그러나 그 이상으로 채우지 않도록 해야한다'는 것은 파이프가 가득찬 상태에서는 큰 큐가 쌓이도록 허용되는 경우가 좋을게 없음을 의미한다.  


## 공평성  

각각 다른 종단간의 경로를 갖지만, 모두 Rbps의 전송률인 병목링크를 지나는 k개의 TCP 연결을 생각해보자.  
각 연결은 큰 파일을 전송하고 있고, 병목 링크를 통과하는 UDP 트래픽은 없다고 가정하자.  
각 연결의 평균 전송률이 R/k에 가깝다면 혼잡제어 매커니즘이 공평하다고 한다. 즉, 각 연결은 링크 대역폭을 공평하게 공유한다.  

서로다른 TCP 연결들이 서로다른 시점에서 시작하고, 주어진 시점에서 다른 윈도크기를 갖는다고 했을 때, TCP의 AIMD 알고리즘은 공평한가?는 경쟁하는 TCP 연결 사이에서 병목링크의 대역폭을 공평하게 공유하도록 왜 TCP 혼잡제어가 한 곳으로 수렴하는지에 대해 훌륭하고 직관적인 설명을 제공한다.  

전송률이 R인 링크 하나를 공유하는 2개의 TCP 연결이라는 간단한 경우를 고려해보자.  
두 연결이 같은 MSS와 RTT를 가지며 송신할 많은 양의 데이터가 있고, 어떠한 다른 TCP 연결이나 UDP 데이터그램도 이 공유된 링크를 통과하지 않는다고 가정한다.  
또 한 TCP의 슬로 스타트 현상을 무시하고, TCP 연결이 언제나 혼잡회피 방식으로 동작한다고 가정할 것이다.  

만약 TCP가 두 연결 사이에서 링크 대역폭을 똑같이 공유한다면, 실제 처리율은 원점에서부터 발산하면서 45도 각도의 화살표를 따라야 한다.  
이상적으로는 두 처리율의합이 R과 같아야 한다.  
그래서 목적은 동등한 대역폭 공유 선과 완전한 대역폭 이용선의 교차지점 가까운 곳의 처리율을 얻는 것이다.  

TCP 윈도 크기가 어느 주어진 시점에서 연결 1과 2가 A지점으로 나타내는 처리율을 실현한다고 하자.  
두 연결에 의해 공동으로 소비되는 링크 대역폭의 양이 R보다 적으므로, 어떠한 손실도 발생하지 않을 것이다.  

그리고 양 연결은 TCP 혼잡회피 알고리즘의 결과로서 RTT당 1MSS씩 이들의 윈도를 증가시킬 것이다.  
그러므로 두 연결의 공통 처리율은 A지점에서 시작하는 45도 각도의 선을 따라 계속 된다.  

결국 두 연결에 의해 공동으로 소비되는 링크 대역폭은 R보다 커질 것이고, 패킷 손실이 발생한다.  
연결 1과 2는 반으로 그들의 윈도를 감소시킨다.  

결과적으로 실현된 처리율은 C에 있게 되는데, B와 원점의 중간이다.  
공동 대역폭 사용이 C지점에서 R보다 낮으므로, 두 연결은 다시 C로부터 시작하는 45도 선을 따라 처리율을 증가시킨다.  

결국 손실이 다시 발생할 것이고(D지점), 두 연결은 다시 반으로 윈도 크기를 감소시킨다.  

두 연결에 의해 실현되는 대역폭이 똑같은 대역폭 공유 선을 따라서 결국 변동한다는 것을 확신해야 한다.  
또한 두 연결이 2차원 공간 어디에 있든지 간에 상관없이 수렴한다는 사실을 알아야 한다.  
비록 많은 이상적인 가정이 이 시나리오에 놓여있긴 하지만 왜 TCP가 연결 사이에서 대역폭을 똑같이 공유하는 지에 대한 느낌을 여전히 제공한다.  

우리는 이상적인 시나리오에서는 2개의 TCP연결만이 병목링크를 통과하고 연결들은 같은 RTT값을 가지며, 단일 TCP 연결만이 호스트-목적지 쌍과 관련된다고 가정했다.  
현실에서 이런 조건들이 일반적으로 만족하지않는다.  

클라이언트-서버 애플리케이션들은 링크 대역폭의 각기 다른 양을 얻을 수 있다.  
특히 여러 연결이 공통의 병목링크를 공유할 때, 더 작은 RTT를 갖는 세션은 대역폭이 더 빠르게 비워지므로 링크에서 가용한 대역폭을 점유할 수 있고(빠르게 혼잡 윈도를 개방) 그래서 큰 RTT를 갖는 연결보다 더 높은 처리율을 가진다.  

## 공평성과 UDP

UDP 상에서 동작할 떄, 애플리케이션은 혼잡시 '공평한'레벨로 그들의 등급을 낮추고 어떠한 패킷도 손실하지 않기 보다는 일정한 속도로 네트워크에 오디오와 비디오를 공급하기를 좋아하지만 떄론 패킷을 잃는다.  

UDP는 다른 연결들과 협력하지도 않으며, 그들의 전송률을 적당하게 조절하지도 않는다.  
TCP 혼잡제어는 혼잡(손실) 증가에 따라 전송률을 감소시키므로 그럴 필요가 없는 UDP 송신자들이 TCP 트래픽을 밀어낼 가능성이 있다.  

## 공평성과 병렬 TCP 연결  

만약 우리가 UDP 트래픽을 공평하게 행동하도록 강요하더라도, 공평성 문제는 여전히 완벽하게 해결되지 않을 것이다.  
왜냐하면 TCP 기반 애플리케이션의 다중 병렬 연결의 사용을 막을 방법이 없기 떄문이다.  

애플리케이션이 다중 병렬연결을 사용할 때는 혼잡한 링크 대역폭의 더 많은 부분을 차지한다.  

예를 들어 9개의 진행중인 클라이언트-서버 애플리케이션을 지원하는 전송률 R링크를 고려하자.  
각 애플리케이션은 하나의 TCP 연결을 사용한다.  
만약 새로운 애플리케이션이 만들어지고 또 하나의 TCP 연결을 사용한다면 각 애플리케이션은 대체로 같은 R/10 전송률을 가진다.  

그러나 만약 새로운 애플리케이션이 11개의 병렬 TCP 연결을 사용한다면, 새로운 애플리케이션은 R/2보다 많은 불공평한 할당을 받는다.  













